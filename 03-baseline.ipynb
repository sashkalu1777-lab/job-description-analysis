{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a81a4267",
   "metadata": {},
   "source": [
    "# Baseline without RAG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639c1bf4",
   "metadata": {},
   "source": [
    "Import packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3438b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from json import loads, dumps\n",
    "from langchain.tools import tool\n",
    "# from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Annotated, Sequence, TypedDict, Literal\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# from langchain_chroma import Chroma\n",
    "# from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langfuse import Langfuse, get_client\n",
    "from langfuse.langchain import CallbackHandler\n",
    "from langfuse.openai import openai  # Don't delete this line.\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import tools_condition, ToolNode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222df19d",
   "metadata": {},
   "source": [
    "Set up environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "696f7d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Set up environment variables.\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Monitor if the environment variables are ready.\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set - please head to the troubleshooting guide in the setup folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5736d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langfuse client is authenticated and ready!\n"
     ]
    }
   ],
   "source": [
    "langfuse_secret_key = os.getenv('LANGFUSE_SECRET_KEY')\n",
    "langfuse_public_key = os.getenv('LANGFUSE_PUBLIC_KEY')\n",
    "langfuse = Langfuse(\n",
    "    secret_key = langfuse_secret_key,\n",
    "    public_key = langfuse_public_key,\n",
    "    host=\"https://cloud.langfuse.com\"\n",
    "    # host = \"https://us.cloud.langfuse.com\"\n",
    ")\n",
    "\n",
    "langfuse = get_client()\n",
    " \n",
    "# Verify connection\n",
    "if langfuse.auth_check():\n",
    "    print(\"Langfuse client is authenticated and ready!\")\n",
    "else:\n",
    "    print(\"Authentication failed. Please check your credentials and host.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45a89de",
   "metadata": {},
   "source": [
    "Define supporting variables and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7a2f731",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    # \"vector_store_directory\": \"./chroma_db\",\n",
    "    # \"vector_store_collection_name\": \"langchain_rag\",\n",
    "    # \"chunk_size\": 500,\n",
    "    # \"chunk_overlap\": 50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d26637a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_job_descriptions(jd_dataframe):\n",
    "    if isinstance(jd_dataframe, pd.Series):\n",
    "        jd_dataframe = jd_dataframe.to_frame().T\n",
    "    result = jd_dataframe.to_json(orient='records')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6542a8e",
   "metadata": {},
   "source": [
    "Function test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21b4bb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"title\": \"Driver / Tour Guide for Coach & 4WD Coach Tours\",\n",
      "        \"abstract\": \"This role includes conducting 1-20 Day Tours to a range of locations all over Australia with mature passengers for a well established family company.\",\n",
      "        \"job_description_clean\": \"Casey Australia Tours require a experienced Coach Drivers / Tour Guide for the rest of the 2019 season of extended motel and/or camping tours starting mid/late June The role requires driving, minor coach maintenance, cleaning, guiding and commentating plus some cooking. The ideal person should have; 1. A sense of humour and engaging personality 2. Initiative and problem solving skills 3. Confidence and be a good public speaker 4. A current manual HR drivers licence with F endorsement. (or ability to get one quickly) 5. A safe driving record 6. Clear Criminal History 7. Experience in some field that can be related 8. First Aid Training 9. Good Navigation in remote and city areas Handy assets to have; 1. Mechanical Knowledge 2. Camping experience 3. Group Cooking Experience Our passengers are mainly Australian adults from 50 - 80+ years old. Each tour is run by 1 - 2 Staff caring for up to 48 passengers. It is essential that staff cooperate well and work closely together. This is an interesting, exciting, varied and extremely rewarding role. It's an enjoyable lifestyle with its share of hard days but also has a lot of fun easy days in some stunning locations. To view our range of tours visit www.caseytours.com.au/calendar/ To get a better idea of the places, people and coaches go to our Facebook page, www.facebook.com/CaseyAustraliaTours Rate of Pay $300 - $350 Per day (depending on experience and knowledge) + Super Work is on a tour by tour basis from mid /late June, scheduling is roughly two weeks on and one off but varies. The season goes through to November with ongoing employment for available. For the right applicant the role could be based in nearly any capital city flying in and out to different towns to start and finish tours. If you feel you are up to the challenge, please: 1. Reply to this ad on Seek 2. Send a CV and Cover Letter by email to tcasey@caseytours.com.au\",\n",
      "        \"classification\": \"Hospitality & Tourism\",\n",
      "        \"subClassification\": \"Tour Guides\",\n",
      "        \"area\": null,\n",
      "        \"location\": \"Perth\",\n",
      "        \"suburb\": null,\n",
      "        \"workType\": \"Casual/Vacation\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/X_test.csv\")\n",
    "test = df.iloc[0, :]\n",
    "if isinstance(test, pd.Series):\n",
    "        test = test.to_frame().T\n",
    "json_records = test.to_json(orient='records')\n",
    "parsed = loads(json_records)\n",
    "print(dumps(parsed, indent=4) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96280d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def check_basic_information(job_descriptions) -> dict:\n",
    "    \"\"\"\n",
    "    This function consumes job_descriptions and return basic information with good formatted strings.\n",
    "    \"\"\"\n",
    "    if isinstance(job_descriptions, pd.Series):\n",
    "        job_descriptions = job_descriptions.to_frame().T\n",
    "\n",
    "    list_of_dicts = job_descriptions.to_dict(orient='records')\n",
    "    \n",
    "    jobs_info = []\n",
    "    for i, job_dict in enumerate(list_of_dicts):\n",
    "        jobs_info.append({\n",
    "            \"job_index\": i,\n",
    "            \"fields\": job_dict\n",
    "        })\n",
    "\n",
    "    result = {\n",
    "        \"summary\": \"The information of each job advertisement is as follows.\",\n",
    "        \"jobs\": jobs_info\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "tools = [check_basic_information]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f70729",
   "metadata": {},
   "source": [
    "Define Graph Sate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0089e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of graph.\n",
    "\n",
    "    Attributes:\n",
    "        messages: A list of messages in the conversation, including user input and agent outputs.\n",
    "\n",
    "    Notes:\n",
    "        The add_messages function defines how an update should be processed.\n",
    "        Default is to replace. add_messages says \"append\".\n",
    "    \"\"\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbf385b",
   "metadata": {},
   "source": [
    "Deinfe Basic Nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de3a90f",
   "metadata": {},
   "source": [
    "Input: job description strings.\n",
    "\n",
    "Host node\n",
    "\n",
    "Conditional Edge: whether the question is about to check job descriptions.\n",
    "\n",
    "If not, return generate.\n",
    "\n",
    "If yes, go to next node.\n",
    "\n",
    "Get industry information and professional skills.\n",
    "\n",
    "Get general requirements.\n",
    "\n",
    "Evaluate the job advertisement.\n",
    "\n",
    "Refine the job advertisement.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff364ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def host_agent(state):\n",
    "    \"\"\"\n",
    "    Invokes the whole workflow and monitor the state.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the agent response appended to messages\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"---CALL HOST AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "    model = ChatOpenAI(temperature=0, streaming=True, model=\"gpt-4-turbo\")\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a8e474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def industry_agent(state, job_ads):\n",
    "    \"\"\"\n",
    "    Generate answer. The core of RAG.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "         dict: The updated state with re-phrased question\n",
    "    \"\"\"\n",
    "    print(\"---CALL INDUSTRY AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "            You are a helpful assistant that extracts structured information from a batch of job advertisements.\n",
    "\n",
    "            Input job ad:\n",
    "            {job_text}\n",
    "\n",
    "            Instruction:\n",
    "            Extract the following fields from the given batch of different job ads. If a field is not present, return an empty list for that field.\n",
    "\n",
    "            - skills: short list of skills, tools, technologies (e.g., \"Python\", \"SQL\", \"scikit-learn\", \"communication\")\n",
    "            - responsibilities: short concise list of responsibilities / duties described in the ad\n",
    "            - requirements: candidate requirements such as experience, qualifications, degrees, certifications, years of experience\n",
    "\n",
    "            Return a list of JSON objects ONLY with keys: \"job_titles\", \"skills\", \"responsibilities\", \"requirements\". \n",
    "\n",
    "            Example:\n",
    "            {\n",
    "            {\"job_title\": [\"Data Scientist\"], \"skills\": [\"Python\", \"SQL\"], \"responsibilities\": [\"build predictive models\"], \"requirements\": [\"3+ years experience\", \"Bachelor's degree\"]}\n",
    "            {\"job_title\": [\"Primary Teacher\"], \"skills\": [\"Education\", \"Child Care\"], \"responsibilities\": [\"Give courses\"], \"requirements\": [\"5+ years experience\", \"Master's degree\"]}\n",
    "            }\n",
    "        \"\"\",\n",
    "        input_variables=[\"job_text\"],\n",
    "    )\n",
    "\n",
    "    # LLM\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4-turbo\", temperature=0, streaming=True)\n",
    "\n",
    "    # Chain\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # Run\n",
    "    response = chain.invoke({\"job_text\": job_ads})\n",
    "    print(response)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1362637a",
   "metadata": {},
   "source": [
    "Define conditional edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4c4c9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional Edge: whether the question is about to check job descriptions.\n",
    "\n",
    "def check_task_agent(state, config) -> Literal[\"industry_agent\", \"host_agent\"]:\n",
    "    \"\"\"\n",
    "    Determines whether the question is about to check job descriptions.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        str: A decision for whether the question is about to check job descriptions.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK TASK RELEVANCE---\")\n",
    "\n",
    "    # Pydantic to ensure the output format.\n",
    "    class grade(BaseModel):\n",
    "        \"\"\"Binary score for relevance check.\"\"\"\n",
    "        binary_score: str = Field(description=\"Task relevance score 'yes' or 'no'\")\n",
    "\n",
    "    # LLM\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4o\", streaming=True)\n",
    "\n",
    "    # LLM with tool and validation\n",
    "    llm_with_tool = model.with_structured_output(grade)\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "            You are a grader assessing relevance of user's question and job advertisement analysis task. \\n \n",
    "            Here is the user question: {question} \\n\n",
    "            If the question contains keyword(s) or semantic meaning related to job advertisement analysis, grade it as relevant. \\n\n",
    "            Give a binary score 'yes' or 'no' score to indicate whether the user question is relevant to job advertisement analysis.\n",
    "        \"\"\",\n",
    "        input_variables=[\"question\"],\n",
    "    )\n",
    "\n",
    "    # Chain\n",
    "    chain = prompt | llm_with_tool\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    question = config[\"configurable\"][\"questions\"][-1]\n",
    "    print(\"User question:\\n\", question)\n",
    "    \n",
    "\n",
    "    scored_result = chain.invoke({\"question\": question})\n",
    "\n",
    "    score = scored_result.binary_score\n",
    "\n",
    "    if score == \"yes\":\n",
    "        print(\"---DECISION: This is a job advertisement analysis task. ---\")\n",
    "        return \"industry_agent\"\n",
    "\n",
    "    else:\n",
    "        print(\"---DECISION: This is not a job advertisement analysis task.---\")\n",
    "        return \"host_agent\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfbc4e0",
   "metadata": {},
   "source": [
    "Complie the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cde32e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the nodes.\n",
    "# workflow.add_node(\"host_agent\", host_agent)  \n",
    "workflow.add_node(\"industry_agent\", industry_agent)  \n",
    "\n",
    "# Call agent node to decide to retrieve or not\n",
    "# workflow.add_edge(START, \"host_agent\")\n",
    "\n",
    "workflow.add_edge(START, \"industry_agent\")\n",
    "\n",
    "# Decide whether to retrieve\n",
    "# workflow.add_conditional_edges(\n",
    "#     \"host_agent\",\n",
    "#     check_task_agent,\n",
    "# )\n",
    "# workflow.add_edge(\"host_agent\", \"industry_agent\")\n",
    "workflow.add_edge(\"industry_agent\", END)\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile(checkpointer=MemorySaver())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35b548aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1780a88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_invoke(graph, question, config):\n",
    "    \"\"\"\n",
    "    Invoke the workflow with user question, generate human-friendly metrics and answers.\n",
    "\n",
    "    Args:\n",
    "        graph: The current workflow\n",
    "        question: The user input to invoke the workflow\n",
    "        config: The holder of thread, memory, and LangFuse\n",
    "\n",
    "    Returns:\n",
    "        retriever_counter: how many times the retriever tool is called for this question\n",
    "        rewrite_counter: how many times the question is rewritten, which indicates a failed retrieval\n",
    "        final_message: the answer that can be shown to all audience\n",
    "    \"\"\"\n",
    "    config[\"configurable\"][\"questions\"].append(question)\n",
    "    print(\"config\", config)\n",
    "\n",
    "    final_message = \"\"\n",
    "\n",
    "    inputs = {\n",
    "        \"messages\":[\n",
    "            (\"user\", question)\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    for output in graph.stream(inputs, config=config):\n",
    "        for key, value in output.items():\n",
    "            # For Agent node, output tool call information.\n",
    "            if key == 'host_agent':\n",
    "                final_message = final_message + value['messages'][0].content\n",
    "                print(final_message)\n",
    "            # For retrieve tool node, counter plus.\n",
    "            elif key == 'industry_agent':\n",
    "                final_messsage = final_message + value['messages'][0]\n",
    "                print(final_message)\n",
    "                print(\"\\n---END QUESTION---\")\n",
    "            else:\n",
    "                pass\n",
    "            print(final_message)\n",
    "    return final_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abc3f3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_with_single_question(logs, graph, question, config):\n",
    "    \"\"\"\n",
    "    Deal with the workflow inputs and outputs, push them into local logging system.\n",
    "\n",
    "    Args:\n",
    "        logs: the list to store key information and metrics for the whole thread\n",
    "        graph: The current workflow\n",
    "        question: The user input to invoke the workflow\n",
    "        config: The holder of thread, memory, and LangFuse\n",
    "    \"\"\"\n",
    "    # Get the current date and time for time stamp.\n",
    "    invoke_datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    final_message = agent_invoke(graph, question, config)\n",
    "    thread_id = config['configurable']['thread_id']\n",
    "    row =  [thread_id, invoke_datetime, question, final_message]\n",
    "    logs.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83509f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"0\", \"questions\": []}}\n",
    "logs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cac35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/X_test.csv\")\n",
    "test = df.iloc[0, :]\n",
    "if isinstance(test, pd.Series):\n",
    "        test = test.to_frame().T\n",
    "json_records = test.to_json(orient='records')\n",
    "parsed = loads(json_records)\n",
    "print(dumps(parsed, indent=4) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7df94328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config {'configurable': {'thread_id': '0', 'questions': [\"Hi, I'm Alexandra. Please help me analyse following job advertisements\"]}}\n",
      "---CALL HOST AGENT---\n",
      "Hello Alexandra! I'd be happy to help you analyze the job advertisements you have. Please provide the details of the job advertisements you'd like to discuss, and let me know what specific aspects you want to focus on (e.g., job requirements, qualifications, company culture, etc.).\n",
      "Hello Alexandra! I'd be happy to help you analyze the job advertisements you have. Please provide the details of the job advertisements you'd like to discuss, and let me know what specific aspects you want to focus on (e.g., job requirements, qualifications, company culture, etc.).\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "industry_agent() missing 1 required positional argument: 'job_ads'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdeal_with_single_question\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHi, I\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mm Alexandra. Please help me analyse following job advertisements\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mdeal_with_single_question\u001b[39m\u001b[34m(logs, graph, question, config)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Get the current date and time for time stamp.\u001b[39;00m\n\u001b[32m     12\u001b[39m invoke_datetime = datetime.now().strftime(\u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m_\u001b[39m\u001b[33m%\u001b[39m\u001b[33mH\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m final_message = \u001b[43magent_invoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m thread_id = config[\u001b[33m'\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     15\u001b[39m row =  [thread_id, invoke_datetime, question, final_message]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36magent_invoke\u001b[39m\u001b[34m(graph, question, config)\u001b[39m\n\u001b[32m     18\u001b[39m final_message = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     20\u001b[39m inputs = {\n\u001b[32m     21\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m:[\n\u001b[32m     22\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, question)\n\u001b[32m     23\u001b[39m     ]\n\u001b[32m     24\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# For Agent node, output tool call information.\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhost_agent\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\langgraph\\pregel\\main.py:2674\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2672\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2673\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2674\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2675\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2677\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2679\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2680\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2681\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2682\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2683\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2684\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\langgraph\\pregel\\_runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\langgraph\\_internal\\_runnable.py:657\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\langgraph\\_internal\\_runnable.py:401\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    399\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[31mTypeError\u001b[39m: industry_agent() missing 1 required positional argument: 'job_ads'",
      "During task with name 'industry_agent' and id 'f165f298-8104-6aec-4c88-d84ab1b995b6'"
     ]
    }
   ],
   "source": [
    "deal_with_single_question(logs, graph, \"Hi, I'm Alexandra. Please help me analyse following job advertisements\", config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
